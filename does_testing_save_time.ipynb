{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does Testing Save Time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T = r_{\\rm code} l + r_{\\rm test} l + t_{\\rm DB}$,\n",
    "where\n",
    "* $T \\equiv$ total time spent coding\n",
    "* $l \\equiv$ number of lines of code\n",
    "* $r_{\\rm code} \\equiv$ time spent writing the code itself per line of code\n",
    "* $r_{\\rm test} \\equiv$ time spent writing the testing code per line of code\n",
    "* $t_{\\rm DB} \\equiv$ time spent debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time spent Debugging\n",
    "\n",
    "Let's breakdown that last term a little more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$t_{\\rm DB} = n_l t_l + n_m t_m$, where\n",
    "* $n_l \\equiv$ number of bugs that are easily locatable\n",
    "* $t_l \\equiv$ time spent fixing an easily locatable bug\n",
    "* $n_m \\equiv$ number of bugs that are in a mysterious, hard-to-find location\n",
    "* $t_m \\equiv$ time spent fixing a hard-to-find bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a bit of re-ordering this becomes\n",
    "\n",
    "$t_{\\rm DB} = n_{\\rm caught} t_l ( 1 + f_m \\frac{( t_m - t_l )}{t_l} )$, where\n",
    "* $n_{\\rm caught} \\equiv$ number of bugs caught\n",
    "* $f_m \\equiv$ fraction of bugs that are in a mystery location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can break down $n_{\\rm caught}$ into\n",
    "\n",
    "$n_{\\rm caught} \\equiv f_{c} n = f_{c} e l$, where\n",
    "* $f_{c} \\equiv$ the fraction of bugs that are caught\n",
    "* $n \\equiv$ total number of bugs in the code\n",
    "* $e \\equiv$ number of bugs per line of code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore\n",
    "\n",
    "$t_{\\rm DB} = l f_c e t_l ( 1 + f_m \\frac{( t_m - t_l )}{t_l} )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final parametrized form to explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting everything together, we get\n",
    "\n",
    "$T/l = r_{\\rm code} + r_{\\rm test} + f_c e t_l ( 1 + f_m \\frac{( t_m - t_l )}{t_l} )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we do/don't do testing we can expect that the only values that change are $r_{\\rm test}$, $f_c$, and $f_m$.\n",
    "Therefore we can explore the ratio\n",
    "\n",
    "$T_{\\rm testing} / T_{\\rm no~testing} = (r_{\\rm code} + r_{\\rm test} + f_{c,t} e t_l ( 1 + f_{m,t} \\frac{( t_m - t_l )}{t_l} )) / (r_{\\rm code} + f_{c,n} e t_l ( 1 + f_{m,n} \\frac{( t_m - t_l )}{t_l} ))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/Downloads/Coding Habits Survey (Responses Cleaned) - Form Responses 1.csv', header=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop( 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's actually explore the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_coding_per_line( r_code, r_test, e, t_l, t_m, f_c, f_m,  ):\n",
    "        \n",
    "    return r_code + r_test + f_c * e * t_l * ( 1. + f_m * ( t_m - t_l ) / t_l )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vs_no_test( r_code, r_test, e, t_l, t_m, f_c_test, f_m_test, f_c_notest, f_m_notest ):\n",
    "    \n",
    "    results = []\n",
    "    for i, (f_c, f_m) in enumerate( zip( [ f_c_test, f_c_notest ], [ f_m_test, f_m_notest ] ) ):\n",
    "        \n",
    "        # During the new-test case there should be no time spent testing, ofc\n",
    "        if i == 1:\n",
    "            r_test = 0.\n",
    "                \n",
    "        results.append( time_coding_per_line( r_code, r_test, e, t_l, t_m, f_c, f_m,  ) )\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_parameters = {\n",
    "    'r_code': df['r_code'].values.astype( float ),\n",
    "    'r_test': df['r_code'].values.astype( float ), # We'll assume it takes just as long to test as to code, a conservative assumption\n",
    "    'e': df['e'].values.astype( float ),\n",
    "    't_l': df['t_l'].values.astype( float ),\n",
    "    't_m': df['t_m'].values.astype( float ),\n",
    "    'f_c_notest': 1. - df['1 - f_c_notest'].values.astype( float ),\n",
    "    'f_m_notest': 1. - df['1 - f_m_notest'].values.astype( float ),\n",
    "    'f_c_test': 1. - df['1 - f_c_test'].values.astype( float ),\n",
    "    'f_m_test': 1. - df['1 - f_m_test'].values.astype( float ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't allow f_c_test to fall below f_c_no_test\n",
    "invalid = estimated_parameters['f_c_test'] <= estimated_parameters['f_c_notest']\n",
    "# Assume we catch half the remaining bugs\n",
    "estimated_parameters['f_c_test'][invalid] = (\n",
    "    estimated_parameters['f_c_notest'][invalid] +\n",
    "    ( 1. - estimated_parameters['f_c_notest'][invalid] ) * 0.5\n",
    ")\n",
    "print( 'Fixed {} invalid f_c_test values'.format( invalid.sum() ) )\n",
    "\n",
    "# Don't allow f_m_notest to fall below f_m_test\n",
    "invalid = estimated_parameters['f_m_test'] >= estimated_parameters['f_m_notest']\n",
    "# Assume half the remaining bugs are now easy to find\n",
    "estimated_parameters['f_m_test'][invalid] = estimated_parameters['f_m_notest'][invalid] * 0.5\n",
    "print( 'Fixed {} invalid f_m_test values'.format( invalid.sum() ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat\n",
    "import verdict\n",
    "responses = {}\n",
    "for key, item in estimated_parameters.items():\n",
    "    responses[key] = {}\n",
    "    for i, v in enumerate( item ):\n",
    "        responses[key][i] = v\n",
    "responses = verdict.Dict( responses ).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results\n",
    "for i, parameters in responses.items():\n",
    "    result = test_vs_no_test( **parameters )\n",
    "    print( '{:>7.2g} min per line w/ testing, {:>7.2g} min per line w/o, {:>7.2g} ratio, {:>7.2g} df_m, {:>7.2g} df_c'.format(\n",
    "            result[0], \n",
    "            result[1], \n",
    "            result[0]/result[1],\n",
    "            parameters['f_m_test'] - parameters['f_m_notest'],\n",
    "            parameters['f_c_test'] - parameters['f_c_notest'],\n",
    "        )\n",
    "    )\n",
    "    responses[i]['T/l test'], responses[i]['T/l notest'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
